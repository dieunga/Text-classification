{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a67f24",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics\n",
    "!pip install --quiet vietocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cccba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install paddlepaddle==3.1.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/\n",
    "!python3 -m pip install paddlepaddle-gpu==3.1.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/\n",
    "!pip install paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7156f9e9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from paddleocr import TextDetection\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c6620a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "input_folder = '/content/drive/MyDrive/sample_intern1/sample'\n",
    "pdf_output_folder = '/content/drive/MyDrive/sample_intern1/output/pdf_first_pages'\n",
    "img_output_folder = '/content/drive/MyDrive/sample_intern1/output/img_first_pages'\n",
    "os.makedirs(pdf_output_folder, exist_ok=True)\n",
    "os.makedirs(img_output_folder, exist_ok=True)\n",
    "\n",
    "# Loop through PDF files\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Extract first page and save as new PDF\n",
    "        reader = PdfReader(file_path)\n",
    "        writer = PdfWriter()\n",
    "        if len(reader.pages) > 0:\n",
    "            writer.add_page(reader.pages[0])\n",
    "            pdf_output_path = os.path.join(pdf_output_folder, f'{base_name}_page1.pdf')\n",
    "            with open(pdf_output_path, 'wb') as out_pdf:\n",
    "                writer.write(out_pdf)\n",
    "            print(f'‚úÖ Saved first page: {pdf_output_path}')\n",
    "\n",
    "            # Convert first page to image\n",
    "            images = convert_from_path(pdf_output_path, first_page=1, last_page=1)\n",
    "            img_output_path = os.path.join(img_output_folder, f'{base_name}_page1.jpg')\n",
    "            images[0].save(img_output_path, 'JPEG')\n",
    "            print(f'üñºÔ∏è Converted to image: {img_output_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd0400",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/content/drive/MyDrive/sample_intern1/dataset.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07efd78",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = YOLO(\"/content/drive/MyDrive/sample_intern1/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"/content/drive/MyDrive/sample_intern1/dataset.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05959180",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh\n",
    "image_folder = \"/content/drive/MyDrive/sample_intern1/output/img_first_pages\"\n",
    "output_dir = \"/content/drive/MyDrive/sample_intern1/output/test/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# T·∫£i m√¥ h√¨nh YOLO\n",
    "model_crop = YOLO(\"/content/drive/MyDrive/sample_intern1/best.pt\")\n",
    "\n",
    "# Bi·∫øn ƒë·ªÉ ƒë√°nh s·ªë th·ª© t·ª± c√°c ·∫£nh crop\n",
    "crop_count = 0\n",
    "\n",
    "# L·∫∑p qua t·∫•t c·∫£ c√°c file ·∫£nh trong th∆∞ m·ª•c\n",
    "for filename in os.listdir(image_folder):\n",
    "    # Ki·ªÉm tra xem file c√≥ ph·∫£i l√† file ·∫£nh kh√¥ng (jpg, jpeg, png, ...)\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        # ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn ·∫£nh\n",
    "        image_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        # ƒê·ªçc ·∫£nh\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # D·ª± ƒëo√°n tr√™n ·∫£nh\n",
    "        results = model_crop(image)\n",
    "\n",
    "        # Duy·ªát qua t·∫•t c·∫£ c√°c k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "        for result in results:\n",
    "            # Duy·ªát qua t·ª´ng box (bounding box) trong c√°c k·∫øt qu·∫£ d·ª± ƒëo√°n\n",
    "            for box in result.boxes:\n",
    "                # L·∫•y t·ªça ƒë·ªô c·ªßa bounding box (x1, y1, x2, y2)\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "\n",
    "                # Tr√≠ch xu·∫•t v√πng ·∫£nh trong bounding box\n",
    "                object_image = image[y1:y2, x1:x2]\n",
    "\n",
    "                # # T·∫°o t√™n file v·ªõi s·ªë th·ª© t·ª±\n",
    "                output_filename = os.path.join(output_dir, f\"crop_{crop_count}.jpg\")\n",
    "\n",
    "                # L∆∞u ·∫£nh crop v·ªõi t√™n file theo th·ª© t·ª±\n",
    "                cv2.imwrite(output_filename, object_image)\n",
    "\n",
    "                # TƒÉng bi·∫øn ƒë·∫øm\n",
    "                crop_count += 1\n",
    "\n",
    "                print(f\"ƒê√£ l∆∞u {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6df3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "from vietocr.tool.predictor import Predictor\n",
    "from vietocr.tool.config import Cfg\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Kh·ªüi t·∫°o PaddleOCR ch·ªâ d√πng text detection\n",
    "ocr = PaddleOCR(use_angle_cls=False, lang='vi', text_detection_model_name=\"PP-OCRv5_mobile_det\")\n",
    "\n",
    "# Kh·ªüi t·∫°o VietOCR cho text recognition\n",
    "config = Cfg.load_config_from_name('vgg_transformer')\n",
    "config['cnn']['pretrained'] = False\n",
    "config['device'] = 'cuda:0'\n",
    "vietocr_predictor = Predictor(config)\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ·∫£nh ƒë·∫ßu v√†o\n",
    "img_path = '/content/drive/MyDrive/sample_intern1/output/crops/crop_17.jpg'\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Font ƒë·ªÉ v·∫Ω text\n",
    "try:\n",
    "    font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 18)\n",
    "except:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "recognized_text_list = []\n",
    "# T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥\n",
    "os.makedirs(\"output/crops\", exist_ok=True)\n",
    "\n",
    "# Text detection b·∫±ng PaddleOCR\n",
    "result = ocr.ocr(img_path)\n",
    "\n",
    "# L·∫•y dt_polys t·ª´ k·∫øt qu·∫£\n",
    "if result and isinstance(result[0], dict) and 'dt_polys' in result[0]:\n",
    "    for idx, polygon in enumerate(result[0]['dt_polys']):\n",
    "        # polygon l√† numpy array (4, 2), convert th√†nh list point tuple\n",
    "        box_coords = [tuple(map(int, pt)) for pt in polygon]\n",
    "\n",
    "        # T√¨m bounding box\n",
    "        xs = [pt[0] for pt in box_coords]\n",
    "        ys = [pt[1] for pt in box_coords]\n",
    "        x_min, x_max = min(xs), max(xs)\n",
    "        y_min, y_max = min(ys), max(ys)\n",
    "\n",
    "        # Crop v√πng ·∫£nh\n",
    "        cropped = image.crop((x_min, y_min, x_max, y_max))\n",
    "\n",
    "        # L∆∞u ·∫£nh crop\n",
    "        crop_path = f\"output/crops/crop_{idx}.jpg\"\n",
    "        cropped.save(crop_path)\n",
    "\n",
    "        # Nh·∫≠n d·∫°ng vƒÉn b·∫£n b·∫±ng VietOCR\n",
    "        try:\n",
    "            recognized_text = vietocr_predictor.predict(cropped)\n",
    "            recognized_text_list.append(recognized_text)\n",
    "        except:\n",
    "            recognized_text = \"[ERROR]\"\n",
    "\n",
    "        # V·∫Ω polygon + text l√™n ·∫£nh g·ªëc\n",
    "        draw.line(box_coords + [box_coords[0]], fill=(255, 0, 0), width=2)\n",
    "        draw.text((x_min, y_min - 10), recognized_text, fill=(0, 0, 255), font=font)\n",
    "\n",
    "# L∆∞u ·∫£nh k·∫øt qu·∫£\n",
    "image.save(\"output/result_vietocr.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba8ee9a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "recognized_text_list"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
