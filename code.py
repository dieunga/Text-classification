# -*- coding: utf-8 -*-
"""intern_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hgjAAYvCOe-EL2vT8WskZy1Ler8QjUqW
"""

!pip install ultralytics

!python3 -m pip install paddlepaddle==3.1.0 -i https://www.paddlepaddle.org.cn/packages/stable/cpu/
!python3 -m pip install paddlepaddle-gpu==3.1.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/
!pip install paddleocr

# Uninstall conflicting PaddlePaddle versions
!pip uninstall -y paddlepaddle paddlepaddle-gpu

# Reinstall the version compatible with PaddleOCR (replace with the correct version if needed)
!pip install -q paddlepaddle-gpu==2.6.1 -f https://www.paddlepaddle.org.cn/whl/cu113/avx/stable.html
!pip install paddleocr
!pip install paddlex==3.0.0b2

!pip install --quiet vietocr

"""##Chuy·ªÉn t·ª´ file pdf sang ·∫£nh v√† crop ti√™u ƒë·ªÅ th√†nh ·∫£nh

"""

# from ultralytics import YOLO
import os
import matplotlib.pyplot as plt
from PIL import Image
from paddleocr import TextDetection
import cv2
import numpy as np

"""###Chuy·ªÉn c√°c file pdf trong folder sang ·∫£nh"""

# Folder paths
input_folder = '/content/drive/MyDrive/sample_intern1/sample'
pdf_output_folder = '/content/drive/MyDrive/sample_intern1/output/pdf_first_pages'
img_output_folder = '/content/drive/MyDrive/sample_intern1/output/img_first_pages'
os.makedirs(pdf_output_folder, exist_ok=True)
os.makedirs(img_output_folder, exist_ok=True)

# Loop through PDF files
for filename in os.listdir(input_folder):
    if filename.lower().endswith('.pdf'):
        file_path = os.path.join(input_folder, filename)
        base_name = os.path.splitext(filename)[0]

        # Extract first page and save as new PDF
        reader = PdfReader(file_path)
        writer = PdfWriter()
        if len(reader.pages) > 0:
            writer.add_page(reader.pages[0])
            pdf_output_path = os.path.join(pdf_output_folder, f'{base_name}_page1.pdf')
            with open(pdf_output_path, 'wb') as out_pdf:
                writer.write(out_pdf)
            print(f'‚úÖ Saved first page: {pdf_output_path}')

            # Convert first page to image
            images = convert_from_path(pdf_output_path, first_page=1, last_page=1)
            img_output_path = os.path.join(img_output_folder, f'{base_name}_page1.jpg')
            images[0].save(img_output_path, 'JPEG')
            print(f'üñºÔ∏è Converted to image: {img_output_path}')

"""###Train model YOLO ƒë·ªÉ crop ti√™u ƒë·ªÅ c√°c vƒÉn b·∫£n"""

# Load a model
model = YOLO("yolov8n.pt")  # load a pretrained model (recommended for training)

# Train the model
results = model.train(data="/content/drive/MyDrive/sample_intern1/dataset.yaml", epochs=100, imgsz=640)

# Load pretrained model
model = YOLO("/content/drive/MyDrive/sample_intern1/best.pt")  # load a pretrained model (recommended for training)

# Train the model
results = model.train(data="/content/drive/MyDrive/sample_intern1/dataset.yaml", epochs=100, imgsz=640)

"""###Crop t·ª´ng ·∫£nh trong folder"""

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a ·∫£nh
image_folder = "/content/drive/MyDrive/sample_intern1/output/img_first_pages"
output_dir = "/content/drive/MyDrive/sample_intern1/output/test/"
os.makedirs(output_dir, exist_ok=True)

# T·∫£i m√¥ h√¨nh YOLO
model_crop = YOLO("/content/drive/MyDrive/sample_intern1/best.pt")

# Bi·∫øn ƒë·ªÉ ƒë√°nh s·ªë th·ª© t·ª± c√°c ·∫£nh crop
crop_count = 0

# L·∫∑p qua t·∫•t c·∫£ c√°c file ·∫£nh trong th∆∞ m·ª•c
for filename in os.listdir(image_folder):
    # Ki·ªÉm tra xem file c√≥ ph·∫£i l√† file ·∫£nh kh√¥ng (jpg, jpeg, png, ...)
    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
        # ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß ƒë·∫øn ·∫£nh
        image_path = os.path.join(image_folder, filename)

        # ƒê·ªçc ·∫£nh
        image = cv2.imread(image_path)

        # D·ª± ƒëo√°n tr√™n ·∫£nh
        results = model_crop(image)

        # Duy·ªát qua t·∫•t c·∫£ c√°c k·∫øt qu·∫£ d·ª± ƒëo√°n
        for result in results:
            # Duy·ªát qua t·ª´ng box (bounding box) trong c√°c k·∫øt qu·∫£ d·ª± ƒëo√°n
            for box in result.boxes:
                # L·∫•y t·ªça ƒë·ªô c·ªßa bounding box (x1, y1, x2, y2)
                x1, y1, x2, y2 = map(int, box.xyxy[0])

                # Tr√≠ch xu·∫•t v√πng ·∫£nh trong bounding box
                object_image = image[y1:y2, x1:x2]

                # # T·∫°o t√™n file v·ªõi s·ªë th·ª© t·ª±
                output_filename = os.path.join(output_dir, f"crop_{crop_count}.jpg")

                # L∆∞u ·∫£nh crop v·ªõi t√™n file theo th·ª© t·ª±
                cv2.imwrite(output_filename, object_image)

                # TƒÉng bi·∫øn ƒë·∫øm
                crop_count += 1

                print(f"ƒê√£ l∆∞u {output_filename}")

from paddleocr import PaddleOCR
from PIL import Image, ImageDraw, ImageFont
import os

ocr = PaddleOCR(use_angle_cls=True, lang='vi',
                text_detection_model_name="PP-OCRv5_mobile_det")

img_path = '/content/drive/MyDrive/sample_intern1/output/crops/crop_17.jpg'

# OCR inference
result = ocr.ocr(img_path)

# Load image
image = Image.open(img_path).convert('RGB')
draw = ImageDraw.Draw(image)

# Optional: Use a default font
try:
    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 18)
except:
    font = ImageFont.load_default()

# Draw boxes and text
if result and result[0]:
    boxes = result[0]['rec_polys']
    texts = result[0]['rec_texts']
    scores = result[0]['rec_scores']

    for box, text, score in zip(boxes, texts, scores):
        # box is a list of 4 points
        draw.line([(box[0][0], box[0][1]), (box[1][0], box[1][1]), (box[2][0], box[2][1]), (box[3][0], box[3][1]), (box[0][0], box[0][1])], fill=(255, 0, 0), width=2)
        draw.text((box[0][0], box[0][1]), f'{text} ({score:.2f})', fill=(0, 0, 255), font=font)


# Save result
os.makedirs("output", exist_ok=True)
image.save("output/result.jpg")

"""##Text detection (PaddleOCR) v√† text recognition (vietocr)"""

from paddleocr import PaddleOCR
from vietocr.tool.predictor import Predictor
from vietocr.tool.config import Cfg
from PIL import Image, ImageDraw, ImageFont
import os
import numpy as np

# Kh·ªüi t·∫°o PaddleOCR ch·ªâ d√πng text detection
ocr = PaddleOCR(use_angle_cls=False, lang='vi', text_detection_model_name="PP-OCRv5_mobile_det")

# Kh·ªüi t·∫°o VietOCR cho text recognition
config = Cfg.load_config_from_name('vgg_transformer')
config['cnn']['pretrained'] = False
config['device'] = 'cuda:0'
vietocr_predictor = Predictor(config)

# ƒê∆∞·ªùng d·∫´n ·∫£nh ƒë·∫ßu v√†o
img_path = '/content/drive/MyDrive/sample_intern1/output/crops/crop_17.jpg'
image = Image.open(img_path).convert('RGB')
draw = ImageDraw.Draw(image)

# Font ƒë·ªÉ v·∫Ω text
try:
    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 18)
except:
    font = ImageFont.load_default()

recognized_text_list = []
# T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a c√≥
os.makedirs("output/crops", exist_ok=True)

# Text detection b·∫±ng PaddleOCR
result = ocr.ocr(img_path)

# L·∫•y dt_polys t·ª´ k·∫øt qu·∫£
if result and isinstance(result[0], dict) and 'dt_polys' in result[0]:
    for idx, polygon in enumerate(result[0]['dt_polys']):
        # polygon l√† numpy array (4, 2), convert th√†nh list point tuple
        box_coords = [tuple(map(int, pt)) for pt in polygon]

        # T√¨m bounding box
        xs = [pt[0] for pt in box_coords]
        ys = [pt[1] for pt in box_coords]
        x_min, x_max = min(xs), max(xs)
        y_min, y_max = min(ys), max(ys)

        # Crop v√πng ·∫£nh
        cropped = image.crop((x_min, y_min, x_max, y_max))

        # L∆∞u ·∫£nh crop
        crop_path = f"output/crops/crop_{idx}.jpg"
        cropped.save(crop_path)

        # Nh·∫≠n d·∫°ng vƒÉn b·∫£n b·∫±ng VietOCR
        try:
            recognized_text = vietocr_predictor.predict(cropped)
            recognized_text_list.append(recognized_text)
        except:
            recognized_text = "[ERROR]"

        # V·∫Ω polygon + text l√™n ·∫£nh g·ªëc
        draw.line(box_coords + [box_coords[0]], fill=(255, 0, 0), width=2)
        draw.text((x_min, y_min - 10), recognized_text, fill=(0, 0, 255), font=font)

# L∆∞u ·∫£nh k·∫øt qu·∫£
image.save("output/result_vietocr.jpg")

recognized_text_list